import math
import random

from sklearn.metrics import confusion_matrix

import c45
from sklearn import metrics
import numpy as np
from sklearn import tree
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score

from c45 import C45
from pure_ldp.frequency_oracles import LHClient, LHServer

# categorize and bin data
train_df = pd.read_csv("./Dataset/adult.data", header='infer')
train_df.workclass = pd.Categorical(train_df.workclass)
train_df.workclass = train_df.workclass.cat.codes
train_df.education = pd.Categorical(train_df.education)
train_df.education = train_df.education.cat.codes
train_df.marital_status = pd.Categorical(train_df.marital_status)
train_df.marital_status = train_df.marital_status.cat.codes
train_df.occupation = pd.Categorical(train_df.occupation)
train_df.occupation = train_df.occupation.cat.codes
train_df.relationship = pd.Categorical(train_df.relationship)
train_df.relationship = train_df.relationship.cat.codes
train_df.race = pd.Categorical(train_df.race)
train_df.race = train_df.race.cat.codes
train_df.sex = pd.Categorical(train_df.sex)
train_df.sex = train_df.sex.cat.codes
train_df.native_country = pd.Categorical(train_df.native_country)
train_df.native_country = train_df.native_country.cat.codes
train_df.income = pd.Categorical(train_df.income)
train_df.income = train_df.income.cat.codes
train_df.age = pd.qcut(train_df.age, q=10, labels=False, duplicates='drop')
train_df.fnlwgt = pd.qcut(train_df.fnlwgt, q=10, labels=False)
train_df.capital_gain = pd.cut(train_df.capital_gain,10, labels=False)
train_df.capital_loss = pd.cut(train_df.capital_loss,10, labels=False)
train_df.hours_per_week = pd.qcut(train_df.hours_per_week, q=10, labels=False, duplicates='drop')

# run pandas decision tree
T = train_df.iloc[:, 0:-1]
Y = train_df.iloc[:, -1:]
print(train_df)
X_train1, X_test1, y_train1, y_test1 = train_test_split(T, Y, test_size=0.33, random_state=22)
clf = tree.DecisionTreeClassifier()
# clf = clf.fit(X_train1, y_train1)
# predict1 = clf.predict(X_test1)
scores = cross_val_score(clf, T, Y, cv=10)
print('scores')
print(scores)
print(scores.mean())
# print("Accuracy:", metrics.accuracy_score(y_test1, predict1))
print(max(train_df.age))
print(train_df.age.value_counts())
print(train_df.workclass.value_counts())

# these settings have to be adjusted below
epsilon = 10
d = 10
client_olh = LHClient(epsilon=epsilon, d=d, use_olh=True)
server_olh = LHServer(epsilon=epsilon, d=d, use_olh=True)
server_olh2 = LHServer(epsilon=epsilon, d=d, use_olh=True)

# def hash_and_perturb(io):
#     g = client_olh.privatise(io)
#     server_olh.aggregate(g)
#     return g[0]
# returns random value of the support of an encoded and perturbed value
def hash_perturb(io):
    g = client_olh.privatise(io)
    server_olh.aggregate(g)
    return g

def hash_perturb_get0(io):
    return io[0]

def recategorize(io, e, d):
    # g = client_olh.privatise(io)
    # server_olh.aggregate(g)
    # server_olh2.update_params(e,d)
    server_olh2.aggregate(io)
    # # return np.argmax(server_olh2.aggregated_data)
    # winner = np.argwhere(server_olh2.aggregated_data == np.amax(server_olh2.aggregated_data))
    # return np.random.choice(winner.flatten())
    # olh_estimates2 = []
    # add 1 to i
    huu = np.array(olh_estimates2)
    # print('huuu')
    # print(huu)
    for i in range(1, d+1):
        olh_estimates2[i-1] = round(server_olh2.estimate(i,True))
    huu2 = np.subtract(olh_estimates2, huu)
    # print('olh')
    # print(olh_estimates2)
    # print('huuu2')
    # print(huu2)
    winner = np.argwhere(huu2 == np.amax(huu2))
    return np.random.choice(winner.flatten())
    # # print(olh_estimates2)
    # # print(np.argmax(olh_estimates2))
    # # return np.argmax(olh_estimates2)
    # winner = np.argwhere(olh_estimates2 == np.amax(olh_estimates2))
    # return np.random.choice(winner.flatten())
# print(train_df.columns)
# encode and perturb data
perturbed_df_hash = pd.DataFrame()
perturbed_df_hash0 = pd.DataFrame()
perturbed_df = pd.DataFrame()
list_estimates = [[]]
list_aggregates = [[]]
for x in train_df.columns:
    if x == 'income':
        perturbed_df[x] = train_df.loc[:, x]
        perturbed_df_hash[x] = train_df.loc[:, x]
        perturbed_df_hash0[x] = train_df.loc[:, x]
    else:
        epsilon = 10
        d = max(train_df[x]) + 1
        # print(d)
        olh_estimates = []
        server_olh.update_params(epsilon, d)
        client_olh.update_params(epsilon, d)
        server_olh2.update_params(epsilon, d)
        olh_estimates2 = np.array([0])
        for i in range(0, d):
            olh_estimates2 = np.append(olh_estimates2,0)
        # print('ol')
        # print(olh_estimates2)
        tempColumn = train_df.loc[:, x].apply(lambda item: hash_perturb(item+1))
        perturbed_df_hash[x] = tempColumn
        tempColumn = perturbed_df_hash.loc[:, x].apply(lambda item: hash_perturb_get0(item))
        perturbed_df_hash0[x] = tempColumn
        tempColumn = perturbed_df_hash.loc[:,x].apply(lambda item: recategorize(item, epsilon, d))
        perturbed_df[x] = tempColumn
        # print('where')
        # print(server_olh.aggregated_data)
        list_aggregates.append(server_olh.aggregated_data)
        for i in range(0, d):
            olh_estimates.append(round(server_olh.estimate(i+1)))
        list_estimates.append(olh_estimates)

print('perturbed_df')
print(perturbed_df_hash)
print(perturbed_df)
print(perturbed_df_hash0)
print('list_estimates')
print(list_estimates)
# print('list_aggregates')
# print(list_aggregates)
print('compare aggregates with estimates')
print(perturbed_df.age.value_counts())
print(list_estimates[1])
print(perturbed_df.workclass.value_counts())
print(list_estimates[2])
print(perturbed_df.native_country.value_counts())
print(list_estimates[14])

# ttest pandas decision tree trained on perturbed data
# Th = perturbed_df_hash0.iloc[:, 0:-1]
# Yh = perturbed_df_hash0.iloc[:, -1:]
# X_train1h, X_test2h, y_train1h, y_test2h = train_test_split(Th, Yh, test_size=0.33, random_state=42)
# clf = C45()
# clf = clf.fit(X_train1h, y_train1h)
# predict1h = clf.predict(X_test2h)
# print("Accuracy on perturbed data, hashed:", metrics.accuracy_score(y_test2h, predict1h))
# clf.printTree()
T2 = perturbed_df.iloc[:, 0:-1]
Y2 = perturbed_df.iloc[:, -1:]
X_train1, X_test2, y_train1, y_test2 = train_test_split(T2, Y2, test_size=0.33, random_state=22)
one=0
two=0
three=0
four=0
five=0
for i in range(5):
    # clf = tree.DecisionTreeClassifier()
    # clf = clf.fit(X_train1, y_train1)
    # predict1 = clf.predict(X_test1)
    # print("Accuracy on unperturbed data:", metrics.accuracy_score(y_test1, predict1))
    # one+=metrics.accuracy_score(y_test1, predict1)
    # clf = tree.DecisionTreeClassifier()
    # clf = clf.fit(X_train1, y_train1)
    # predict1 = clf.predict(X_test2)
    # print("Accuracy on perturbed data:", metrics.accuracy_score(y_test2, predict1))
    # two+=metrics.accuracy_score(y_test2, predict1)
    clfC = C45()
    clfC.fit(X_train1, y_train1)
    predict1C = clfC.predict(X_test2)
    print('predict')
    print(predict1C)
    conf = confusion_matrix(y_test2,predict1C)
    print(conf)
    print("Accuracy on perturbed data C4.5:", metrics.accuracy_score(y_test2, predict1C))
    three+=metrics.accuracy_score(y_test2, predict1C)
    # clfC.printTree()
    clfC = C45()
    clfC.fit(X_train1, y_train1)
    predict1C = clfC.predict(X_test1)
    print('predict')
    print(predict1C)
    conf = confusion_matrix(y_test1, predict1C)
    print(conf)
    print("Accuracy on unperturbed data C4.5:", metrics.accuracy_score(y_test1, predict1C))
    four += metrics.accuracy_score(y_test1, predict1C)
    clfC = C45()
    clfC.fit(X_train1, y_train1)
    predict1C = clfC.predict(T)
    print('predict')
    print(predict1C)
    conf = confusion_matrix(Y, predict1C)
    print(conf)
    print("Accuracy on original data C4.5:", metrics.accuracy_score(Y, predict1C))
    five += metrics.accuracy_score(Y, predict1C)
print(one/20)
print(two/20)
print(three/20)
print(four/20)
print(five/20)
print('scores')
print(scores)
print(scores.mean())
# clfC.printTree()
# baaaaa2 = pd.DataFrame()
# b2 = [[]]
# ag2 = [[]]
# for x in train_df.columns:
#     if x == 'income':
#         baaaaa2[x] = train_df.loc[:,x]
#     else:
#         d = max(train_df[x]) + 1
#         print(d)
#         olh_estimates = []
#         server_olh.update_params(epsilon=10, d=d)
#         client_olh.update_params(epsilon=10, d=d)
#         tempColumn = train_df.loc[:,x].apply(lambda item: hash_and_perturb(item + 1))
#         baaaaa2[x] = tempColumn
#         ag2.append(server_olh.aggregated_data)
#         for i in range(0, d):
#             olh_estimates.append(round(server_olh.estimate(i + 1)))
#         b2.append(olh_estimates)
#
# print('baaaaa2')
# print(baaaaa2)
# print('b2')
# print(b2)
# print('agg')
# print(ag2)
#
# x = train_df.to_numpy()
# print(x)
# l=[]
# olh_estimates = []
# xx = np.vectorize(lambda item : client_olh.privatise(item))
# #privatised array
# print(xx(x)[0])
#now a function to get the aggregate of the examples you have for each round of the tree algo and an estimate
