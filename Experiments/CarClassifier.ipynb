{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76da44e0",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Get data from the dataset\n",
    "To reconstruct some of the steps in paper from Yilmaz et al. one of the datasets from that paper was used: the car evaluation dataset from UCI Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c18a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       buying  maint doors persons lug_boot safety classification\n",
      "count    1728   1728  1728    1728     1728   1728           1728\n",
      "unique      4      4     4       3        3      3              4\n",
      "top     vhigh  vhigh     2       2    small    low          unacc\n",
      "freq      432    432   432     576      576    576           1210\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "raw_data = pd.read_csv(\"./Dataset/car.data\")\n",
    "\n",
    "print(raw_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27304cf",
   "metadata": {},
   "source": [
    "## Change catergorical data to numeric\n",
    "The different categories that has string values as data are changed in to take on a numeric form in the following manner:\n",
    "\n",
    "|numeric val|buying|maint|doors|persons|lug_boot|safety|classification|\n",
    "|-----------|------|-----|-----|-------|--------|------|--------------|\n",
    "|0|vhigh|vhigh|2|2|small|low|unacc|\n",
    "|1|high|high|3|4|med|med|acc|\n",
    "|2|med|med|4|more|big|high|good|\n",
    "|3|low|low|5more| | | |vgood|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08606462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety  classification\n",
       "0       3      3      0        0         2       1               2\n",
       "1       3      3      0        0         2       2               2\n",
       "2       3      3      0        0         2       0               2\n",
       "3       3      3      0        0         1       1               2\n",
       "4       3      3      0        0         1       2               2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change all the different columns to take on their catergory codes\n",
    "features = raw_data.columns\n",
    "\n",
    "for feature_name in features:\n",
    "    raw_data[feature_name] = pd.Categorical(raw_data[feature_name])\n",
    "    raw_data[feature_name] = raw_data[feature_name].cat.codes\n",
    "\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5cc3f6",
   "metadata": {},
   "source": [
    "# Classification\n",
    "## Naive Bayes classification without LDP\n",
    "Make a simple Naive Bayes classifier with the help of the Scikit-learn python library.\n",
    "The same train/test ratio was used (80%/20%)\n",
    "The classifier is much worse in accuracy (83%) than that from the paper (97%). \n",
    "The goal of this notebook however is to get an overview of all the steps involved in the proces of using LDP data with ML classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8be84db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incorrectly predicted classifications: out of 346 items, 58 are incorrect.\n",
      "Accuracy score: 0.832370: \n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data into features and classes\n",
    "features = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']\n",
    "X = raw_data[features]\n",
    "y = raw_data.classification\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "mnb = CategoricalNB()\n",
    "\n",
    "# Fit data to classifier\n",
    "y_pred = mnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(\"Number of incorrectly predicted classifications: out of %d items, %d are incorrect.\" \n",
    "      %(X_test.shape[0], (y_test != y_pred).sum()))\n",
    "print(\"Accuracy score: %f: \"% (accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b179fbe",
   "metadata": {},
   "source": [
    "# LDP\n",
    "Let's try to make an LDP data encoder to perpurb the data in the dataset\n",
    "## Unary encoding\n",
    "Unary encoding is a simple start and can be used on our different features.\n",
    "Let's start to change just one column of the dataset: the classification.\n",
    "\n",
    "The first two steps will perturb the data.\n",
    "\n",
    "The last step will get an estimate of the frequency of each value in the domain of the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9f3841f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated count per value in the domain: [(2, 1175.6666666666665), (0, 318.99999999999994), (3, 95.66666666666661), (1, 103.99999999999994)]\n",
      "The ACTUAL count per value in the domain: [(2, 1210), (0, 384), (3, 65), (1, 69)]\n"
     ]
    }
   ],
   "source": [
    "# The domain to use is that of the classification column\n",
    "domain = raw_data.classification.unique()\n",
    "\n",
    "# Define 3 functions:\n",
    "# First the encoder, which encodes the response.\n",
    "def encode(response):\n",
    "    return [1 if d == response else 0 for d in domain]\n",
    "\n",
    "# Second the perturbing of the data\n",
    "def perturb(encoded_response):\n",
    "    return [perturb_bit(b) for b in encoded_response]\n",
    "\n",
    "def perturb_bit(bit):\n",
    "    p = .8\n",
    "    q = .2\n",
    "    \n",
    "    sample = np.random.random()\n",
    "    if bit == 1:\n",
    "        if sample <= p:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif bit == 0:\n",
    "        if sample <= q:\n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n",
    "        \n",
    "# Third is the clean up of the amount of 'fake' responses from the perturbed data.\n",
    "# The aggregate of the data will still be valueable, but local data is now still anonimized.\n",
    "def aggregate(responses):\n",
    "    p = .8\n",
    "    q = .2\n",
    "    \n",
    "    # Take the sum of all the columns (axis=0), ie. go over all the bits that represent the encoded response.\n",
    "    sums = np.sum(responses, axis=0)\n",
    "    n = len(responses)\n",
    "    \n",
    "    return [(v - n*q) / (p-q) for v in sums]\n",
    "\n",
    "# per row in the dataset: first encode the classifier into a vector of bit, then perturb that vector.\n",
    "responses = [perturb(encode(i)) for i in raw_data.classification]\n",
    "\n",
    "counts = aggregate(responses)\n",
    "print(\"The estimated count per value in the domain:\", list(zip(domain, counts)))\n",
    "counts = np.sum([encode(i) for i in raw_data.classification], axis=0)\n",
    "print(\"The ACTUAL count per value in the domain:\", list(zip(domain, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9f628f",
   "metadata": {},
   "source": [
    "## Problem connecting to a ML classifier\n",
    "The aggregate function corrects some of the forced fake responses by using a function with p and q. \n",
    "\n",
    "How do we get this last step into a ML classification algorithm?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
