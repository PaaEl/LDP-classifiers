{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76da44e0",
   "metadata": {},
   "source": [
    "# Data\n",
    "## Get data from the dataset\n",
    "To reconstruct some of the steps in paper from Yilmaz et al. one of the datasets from that paper was used: the car evaluation dataset from UCI Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c18a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       buying  maint doors persons lug_boot safety classification\n",
      "count    1728   1728  1728    1728     1728   1728           1728\n",
      "unique      4      4     4       3        3      3              4\n",
      "top     vhigh  vhigh     2       2    small    low          unacc\n",
      "freq      432    432   432     576      576    576           1210\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "raw_data = pd.read_csv(\"./Dataset/car.data\")\n",
    "\n",
    "print(raw_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27304cf",
   "metadata": {},
   "source": [
    "## Change catergorical data to numeric\n",
    "The different categories that has string values as data are changed in to take on a numeric form in the following manner:\n",
    "\n",
    "|numeric val|buying|maint|doors|persons|lug_boot|safety|classification|\n",
    "|-----------|------|-----|-----|-------|--------|------|--------------|\n",
    "|0|vhigh|vhigh|2|2|small|low|unacc|\n",
    "|1|high|high|3|4|med|med|acc|\n",
    "|2|med|med|4|more|big|high|good|\n",
    "|3|low|low|5more| | | |vgood|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08606462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety  classification\n",
       "0       3      3      0        0         2       1               2\n",
       "1       3      3      0        0         2       2               2\n",
       "2       3      3      0        0         2       0               2\n",
       "3       3      3      0        0         1       1               2\n",
       "4       3      3      0        0         1       2               2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change all the different columns to take on their catergory codes\n",
    "features = raw_data.columns\n",
    "\n",
    "for feature_name in features:\n",
    "    raw_data[feature_name] = pd.Categorical(raw_data[feature_name])\n",
    "    raw_data[feature_name] = raw_data[feature_name].cat.codes\n",
    "\n",
    "test_row = raw_data.iloc[-100:]\n",
    "raw_data = raw_data[:-1]\n",
    "\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5cc3f6",
   "metadata": {},
   "source": [
    "# Classification\n",
    "## Naive Bayes classification without LDP\n",
    "Make a simple Naive Bayes classifier with the help of the Scikit-learn python library.\n",
    "The same train/test ratio was used (80%/20%)\n",
    "The classifier is much worse in accuracy (83%) than that from the paper (97%). \n",
    "The goal of this notebook however is to get an overview of all the steps involved in the proces of using LDP data with ML classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8be84db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incorrectly predicted classifications: out of 346 items, 63 are incorrect.\n",
      "Accuracy score: 0.817919: \n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data into features and classes\n",
    "features = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']\n",
    "X = raw_data[features]\n",
    "y = raw_data.classification\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "mnb = CategoricalNB()\n",
    "\n",
    "# Fit data to classifier\n",
    "y_pred = mnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(\"Number of incorrectly predicted classifications: out of %d items, %d are incorrect.\" \n",
    "      %(X_test.shape[0], (y_test != y_pred).sum()))\n",
    "print(\"Accuracy score: %f: \"% (accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b179fbe",
   "metadata": {},
   "source": [
    "# LDP\n",
    "Let's try to make an LDP data encoder to perpurb the data in the dataset\n",
    "## Unary encoding\n",
    "Unary encoding is a simple start and can be used on our different features.\n",
    "Let's start to change just one column of the dataset: the classification.\n",
    "\n",
    "The first two steps will perturb the data.\n",
    "\n",
    "The last step will get an estimate of the frequency of each value in the domain of the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3841f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated count per value in the domain: [(0, 1214.3333333333335), (1, 386.00000000000006), (2, 24.333333333333464), (3, 37.66666666666679)]\n",
      "The ACTUAL count per value in the domain: [(0, 1210), (1, 384), (2, 64), (3, 69)]\n"
     ]
    }
   ],
   "source": [
    "# The domain to use is that of the classification column\n",
    "p = .8\n",
    "q = 1 - p\n",
    "\n",
    "# Define 3 functions:\n",
    "# First the encoder, which encodes the response.\n",
    "def encode(response, domain):\n",
    "    return [1 if d == response else 0 for d in domain]\n",
    "\n",
    "# Second the perturbing of the data\n",
    "def perturb(encoded_response):\n",
    "    return [perturb_bit(b) for b in encoded_response]\n",
    "\n",
    "def perturb_bit(bit):\n",
    "    sample = np.random.random()\n",
    "    if bit == 1:\n",
    "        if sample <= p:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif bit == 0:\n",
    "        if sample <= q:\n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n",
    "        \n",
    "# Third is the clean up of the amount of 'fake' responses from the perturbed data.\n",
    "# The aggregate of the data will still be valueable, but local data is now still anonimized.\n",
    "def aggregate(responses):\n",
    "    # Take the sum of all the columns (axis=0), ie. go over all the bits that represent the encoded response.\n",
    "    sums = np.sum(responses, axis=0)\n",
    "    n = len(responses)\n",
    "    \n",
    "    return [(v - n*q) / (p-q) for v in sums]\n",
    "\n",
    "# per row in the dataset: first encode the classifier into a vector of bit, then perturb that vector.\n",
    "responses = [perturb(encode(i, raw_data.classification.unique())) for i in raw_data.classification]\n",
    "\n",
    "counts = aggregate(responses)\n",
    "\n",
    "print(\"The estimated count per value in the domain:\", list(zip(range(len(raw_data.classification.unique())), counts)))\n",
    "counts = np.sum([encode(i,raw_data.classification.unique()) for i in raw_data.classification], axis=0)\n",
    "print(\"The ACTUAL count per value in the domain:\", list(zip(range(len(raw_data.classification.unique())), counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9f628f",
   "metadata": {},
   "source": [
    "## Problem connecting to a ML classifier\n",
    "The aggregate function corrects some of the forced fake responses by using a function with p and q. \n",
    "\n",
    "How do we get this last step into a ML classification algorithm?\n",
    "\n",
    "Let's recreate the Naive Bayes classifier from the Yilmaz et al. paper.\n",
    "\n",
    "### Split data to fit the Bayes function\n",
    "Here the first step is to encode two pieces of data: \n",
    "- The classification\n",
    "- The feature combined with the classification\n",
    "\n",
    "The first step is straight forward encoding and perturbing of all the classifications.\n",
    "For the second step we need to make the feature dependent on the classification in some way. For this the following function can be used: `(input) * k + v` where k is the number of different class values and v is the actual value for the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c66a04ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example row of features and class:\n",
      "[[0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0], [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0]] [1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Make an array of encoded class values\n",
    "perturbed_classes = [perturb(encode(i, y_train.unique().tolist())) for i in y_train]\n",
    "\n",
    "# Make an array of all the encoded features\n",
    "perturbed_features = []\n",
    "for i in range(len(X_train)):\n",
    "    features_list = []\n",
    "    for feature in features:\n",
    "        input_val = X_train.iloc[i][feature]\n",
    "        k = len(y_train.unique().tolist())\n",
    "        v = y_train.iloc[i]\n",
    "        domain = X_train[feature].unique()\n",
    "        perturbed_input = perturb(encode((input_val) * k + v, range(len(domain) * k)))\n",
    "        features_list.append(perturbed_input)\n",
    "    perturbed_features.append(features_list)\n",
    "\n",
    "print(\"An example row of features and class:\")\n",
    "print(perturbed_features[0],perturbed_classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3de6fa",
   "metadata": {},
   "source": [
    "## Central aggregator\n",
    "### Perform frequency estimation at the data aggregator\n",
    "At the central data aggregator we must now perform a estimate of the frequency of each value of each feature|class pair and class.\n",
    "\n",
    "We need to make two different functions that will return the specific esitmate for a requested feature|class or class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99b5ed9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276.3333333333334"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get frequencies for the classification\n",
    "frequency_class = aggregate(perturbed_classes)\n",
    "frequency_class = [1 if item < 0 else item for item in frequency_class]\n",
    "\n",
    "# Function to make frequency estimation per feature|class value\n",
    "def estimate(feat_val, class_val, feat_name):\n",
    "    domain_class = len(y_train.unique().tolist())\n",
    "    domain_feat = len(X_train[feat_name].unique().tolist())\n",
    "    domain = domain_class * domain_feat\n",
    "    enc_b_g = encode(feat_val * domain_class + class_val, range(domain))\n",
    "\n",
    "# Get the estimates for the different possibilities in the provided data\n",
    "    df = pd.DataFrame(perturbed_features).set_axis(features, axis=1)\n",
    "    buying_estimates = aggregate(df[feat_name].values.tolist())\n",
    "    buying_estimates = [item if item > 0 else 1 for item in buying_estimates]\n",
    "\n",
    "# Now estimate for the frequency of this particular value can be read from the list\n",
    "    b_g_estimate = np.sum([buying_estimates[i] if enc_b_g[i] else 0 for i in range(len(enc_b_g))])\n",
    "    return b_g_estimate\n",
    "\n",
    "# First do it for Fi = x | Cj, so for feature being 'buying = low' given 'good'\n",
    "# Encode 'buying = low' given 'good' (low = 3 and good = 2)\n",
    "estimate(3, 2, 'buying')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc5f7a9",
   "metadata": {},
   "source": [
    "### Convert frequencies to probabilities\n",
    "Now that we have the frequencies for each feature and class we can convert these into probabilties that we can use in the Bayes function.\n",
    "\n",
    "This is done by taking the average of each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38ca9b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29386742289968093"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def probability_class(class_val):\n",
    "    return frequency_class[class_val] / np.sum(frequency_class)\n",
    "\n",
    "# Sum estimates of all values in the domain of buying\n",
    "# Devide secific estimate by sum to get probability\n",
    "\n",
    "def probability_feat_class(feat_val, class_val, feat_name):\n",
    "    sum_feat_class = np.sum([estimate(i, class_val, feat_name) for i in range(len(X_train[feat_name].unique().tolist()))])\n",
    "    return estimate(feat_val, class_val, feat_name) / sum_feat_class\n",
    "\n",
    "probability_feat_class(3,2,'buying')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e526822d",
   "metadata": {},
   "source": [
    "## Perform the Bayes function\n",
    "The Bayes function is now able to give a probability for each class given a certain feature USING our found probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2903f5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43352601156069365\n"
     ]
    }
   ],
   "source": [
    "# We need to calculate the probability for each class with out input values\n",
    "def bayes(input_val):\n",
    "    probs = []\n",
    "    for class_val in range(len(y_train.unique().tolist())):\n",
    "        prob_prod = 1\n",
    "        for feat_num in range(len(features)):\n",
    "            feat_name = features[feat_num]\n",
    "            feat_val = input_val[feat_num]\n",
    "            prob_prod = prob_prod * probability_feat_class(feat_val, class_val, feat_name)\n",
    "        probs.append(prob_prod * probability_class(class_val))\n",
    "    return probs\n",
    "\n",
    "def select_max_classification(results):\n",
    "    classification = []\n",
    "    for item in results:\n",
    "        maximum_value = 0\n",
    "        maximum_index = -1\n",
    "        for i in range(len(item)):\n",
    "            if item[i] > maximum_value:\n",
    "                maximum_value = item[i]\n",
    "                maximum_index = i\n",
    "        classification.append(maximum_index)\n",
    "    return classification\n",
    "\n",
    "# print(pd.DataFrame(bayes(test_row.values.tolist())).transpose())\n",
    "# print(\"Actual classifcation: \", test_row.classification)\n",
    "y_predict = select_max_classification([bayes(row) for row in X_test.values.tolist()])\n",
    "\n",
    "print(accuracy_score(y_predict, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
